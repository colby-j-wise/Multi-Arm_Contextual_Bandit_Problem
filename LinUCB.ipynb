{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class UCBArm creates the LinUCB K-arms of our contextual-bandit.\n",
    "Via the LinUCB1 algorithm, our multi-arm bandit\n",
    "learns to optimize the cumulative take-rate (CTR) and minimize\n",
    "regret log-linearly. Through this optimization our bandit learns\n",
    "in an on-line manner by sequentially updating bandit arms \n",
    "based on an observed reward given a new context vector at each\n",
    "time step. \n",
    "\"\"\"\n",
    "class UCBArm(object):\n",
    "    \"\"\"\n",
    "    Initialization: \n",
    "        All bandits at time step 0 are initialized to\n",
    "        have a DxD design matrix 'A' that is the identity\n",
    "        matrix and 'b' vector init to 0s. \n",
    "    @param:\n",
    "        id - unique arm id (1...K) for each arm\n",
    "        d - length of context vector\n",
    "        alpha  - exploitation rate\n",
    "    \"\"\"\n",
    "    def __init__(self, id, d, alpha):\n",
    "        self.id = id\n",
    "        self.d = d\n",
    "        self.alpha = alpha\n",
    "        # Li lines 5-6\n",
    "        self.A = np.identity(self.d)\n",
    "        self.b = np.zeros((self.d,1))\n",
    "    \n",
    "    \"\"\"\n",
    "    getUCB: \n",
    "        Calculates the ucb given a context vector.\n",
    "        Assumes expected payoff is linear in its\n",
    "        d-dimensional feature vector. When considering\n",
    "        all the arms of the bandit this is performing\n",
    "        ridge regression to predict which arm should\n",
    "        be played given a context vector and using\n",
    "        on all the arms UCBs.\n",
    "    @param:\n",
    "        x - context vector (1 x d)\n",
    "    @return:\n",
    "        ucb - upper confidence bound\n",
    "    \"\"\"\n",
    "    def getUCB(self, x):\n",
    "        Ainv = np.linalg.inv(self.A)\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "        self.thetaHat = np.dot(Ainv, self.b)\n",
    "        self.stdev = np.sqrt(np.dot(np.dot(x.T, Ainv), x))\n",
    "        self.ucb = np.dot(self.thetaHat.T, x) + self.alpha * self.stdev\n",
    "        return self.ucb[0][0]\n",
    "    \n",
    "    \"\"\"\n",
    "    update_arm: \n",
    "        Updates an arm's 'A' matrix and 'b' vector\n",
    "        based on observed reward and context vector\n",
    "    @param:\n",
    "        reward - reward for predicted action\n",
    "        x - context vector (1 x d)\n",
    "    \"\"\"\n",
    "    def update_arm(self, reward, x):\n",
    "        x = np.array(x).reshape(-1,1)\n",
    "        self.A += np.dot(x, np.transpose(x))\n",
    "        self.b += reward * x\n",
    "        return None\n",
    "    \n",
    "    \"\"\"\n",
    "    update_alpha: \n",
    "        Used to update alpha during the training process\n",
    "    @param:\n",
    "        method - alpha update rule\n",
    "        t - None (default); use the time step to update alpha (ex alpha/t)\n",
    "    \"\"\"\n",
    "    def update_alpha(self, method=1, t=None):\n",
    "        if method == 1:\n",
    "            self.alpha /= 2\n",
    "        elif method == 2:\n",
    "            self.alpha -= .001\n",
    "        elif method == 3:\n",
    "            assert t > 0\n",
    "            self.alpha = self.alpha/math.sqrt(t)\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class LinUCB implements Li's LinUCB Algorithm [1]\n",
    "for linear disjoint models for K-arm contextual\n",
    "bandits. \n",
    "\"\"\"\n",
    "class LinUCB(object):\n",
    "    \"\"\"\n",
    "    Initialization: \n",
    "        Creates a bandit and init's it's K arms. \n",
    "    @param:\n",
    "        alpha - expliotation rate\n",
    "        d - length of context vector\n",
    "        n  - number of arms\n",
    "        \n",
    "        arms: dictionary of UCBArms. Basically contains Da and ca\n",
    "              (consequentially Aa also) from the original paper\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, alpha, d, k):\n",
    "        self.alpha = alpha\n",
    "        self.d = d  #100\n",
    "        self.nArms = k #10\n",
    "        \n",
    "        self.arms = self.init_arms()\n",
    "    \n",
    "    \"\"\"\n",
    "    init_arms: \n",
    "        Init nArms of UCBarms\n",
    "    @return:\n",
    "        arms_dict - dictionary of arms of class UCBArm\n",
    "    \"\"\"\n",
    "    def init_arms(self):\n",
    "        arms_dict = {}\n",
    "        for id in range(1, self.nArms + 1):\n",
    "            arms_dict[id] = UCBArm(id, self.d, self.alpha)\n",
    "        return arms_dict\n",
    "    \n",
    "    \"\"\"\n",
    "    get_ucbs: \n",
    "        Calculates ucb for all arms\n",
    "    @param:\n",
    "        x - context vector\n",
    "    @return:\n",
    "        ucbs - dictionary of mappings of v: ucb,  k: arm id\n",
    "    \"\"\"\n",
    "    def get_ucbs(self, x):\n",
    "        ucbs = {}\n",
    "        for arm in self.arms:\n",
    "            ucbs[arm] = self.arms[arm].getUCB(x)\n",
    "        return ucbs\n",
    "    \n",
    "    \"\"\"\n",
    "    choose_arm: \n",
    "        Returns id of arm with maximum ucb. Breaks ties\n",
    "        uniformly at random\n",
    "    @param:\n",
    "        ucbs - dictionary of ucbs for all arms\n",
    "    @return:\n",
    "        arm_id - id of arm with max ucb\n",
    "    \"\"\"\n",
    "    def choose_arm(self, ucbs):\n",
    "        max_ucb = -1\n",
    "        max_ucb_ids = set()\n",
    "        for id, ucb in ucbs.items():\n",
    "            if ucb > max_ucb:\n",
    "                max_ucb_ids = set()\n",
    "                max_ucb_ids.add(id)\n",
    "                max_ucb = ucb\n",
    "            elif ucb == max_ucb:\n",
    "                max_ucb_ids.add(id)\n",
    "        if len(max_ucb_ids) > 1:\n",
    "            return random.sample(max_ucb_ids, 1)[0]\n",
    "        else:\n",
    "            return list(max_ucb_ids)[0]\n",
    "    \n",
    "    \"\"\"\n",
    "    get_reward: \n",
    "        If predicted 'arm' equals true action\n",
    "        reward is 1, else 0\n",
    "    @param:\n",
    "        arm - predicted action/arm for context\n",
    "    @return:\n",
    "        action - true observed action for context\n",
    "    \"\"\"\n",
    "    def get_reward(self, arm, action):\n",
    "        if arm == action:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    \"\"\"\n",
    "    predict: \n",
    "        Helper function that calls the above functions \n",
    "        to predict an action based on a given context vector\n",
    "    @param:\n",
    "        x - context vector\n",
    "    @return:\n",
    "        pred_act - predicted action (arm id)\n",
    "    \"\"\"\n",
    "    def predict(self, x):\n",
    "        ucbs = self.get_ucbs(x)\n",
    "        pred_act = self.choose_arm(ucbs)\n",
    "        return pred_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class LinUCB implements unbiased offline evaluation\n",
    "of our multi-arm contextual bandit following\n",
    "Li, Chu, et. al. [2]. At each time step (2...T)\n",
    "we use our algorithm from t-1 to predict t context\n",
    "vector. We evaluate our bandit's cumulative\n",
    "take-rate over time. \n",
    "\"\"\"\n",
    "class bandit_evaluator(object):\n",
    "    \"\"\"\n",
    "    Initialization: \n",
    "        Creates an evaluator object to store bandit history \n",
    "        and calculate CTR\n",
    "        \n",
    "        bandits:  list to store our trained bandit history\n",
    "        cum_rewards: cumulative rewards earned\n",
    "        ctr_history: CTR history\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.bandits = []\n",
    "        self.cum_rewards = 0\n",
    "        self.ctr_history = []\n",
    "    \n",
    "    \"\"\"\n",
    "    calc_ctr: \n",
    "        Makes prediction for new observed context at time t\n",
    "        using the t-1 bandit and gets rewards then calculates\n",
    "        CTR  \n",
    "    @param:\n",
    "        x - context vector at time t\n",
    "        action - true action for x\n",
    "        t - current time step\n",
    "    @return:\n",
    "        ctr - cumulative take-rate\n",
    "    \"\"\"\n",
    "    def calc_ctr(self, x, action, t):\n",
    "        assert t > 0\n",
    "        bandit = self.bandits[t-1]\n",
    "        pred_act = bandit.predict(x)\n",
    "        if pred_act == action:\n",
    "            self.cum_rewards += 1\n",
    "        ctr = self.cum_rewards/t\n",
    "        self.ctr_history.append(ctr)\n",
    "        return ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import getData, getContext, getAction\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "train: \n",
    "    Main driver function that implements LinUCB1\n",
    "    and trains our multi-arm contextual bandit\n",
    "@param:\n",
    "    file - data file to use (see readme for example)\n",
    "    steps - number of time steps (i.e. total observations in data)\n",
    "    nArms - number of bandit arms (K in paper)\n",
    "    d - dimension of context vector\n",
    "@return:\n",
    "    ctr_history - cumulative take-rate history\n",
    "\"\"\"\n",
    "def train(file, steps, alpha, nArms, d):\n",
    "    # read in data\n",
    "    data = getData(file)\n",
    "    # initialize K-arm bandit\n",
    "    bandit = LinUCB(alpha, d, nArms)\n",
    "    # initialize bandit evaluator \n",
    "    evaluator = bandit_evaluator()\n",
    "    \n",
    "    for t in range(steps):  \n",
    "        x = getContext(data, t)\n",
    "        action = getAction(data, t)\n",
    "        arm = bandit.predict(x)\n",
    "        reward = bandit.get_reward(arm, action)\n",
    "        bandit.arms[arm].update_arm(reward, x)\n",
    "        \n",
    "        if t > 0: # explore various alpha update methods to improve CTR\n",
    "            bandit.arms[arm].update_alpha(method=1) # or method=2\n",
    "            #bandit.arms[arm].update_alpha(3, t)\n",
    "        \n",
    "        if t > 0: # evaluate current bandit algorithm\n",
    "            evaluator.bandits.append(bandit)\n",
    "            ctr = evaluator.calc_ctr(x, action, t)\n",
    "            if t % 100 == 0:\n",
    "                print(\"Step:\", t, end=\"\")\n",
    "                print(\" | CTR: {0:.02f}%\".format(ctr))\n",
    "    return evaluator.ctr_history\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"classification.txt\"\n",
    "steps = 10000\n",
    "alpha = .1\n",
    "nArms = 10\n",
    "dim = 100\n",
    "\n",
    "ctr_history = train(file2, steps, alpha, nArms, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dianogstics\n",
    "print(ctr_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp",
   "language": "python",
   "name": "pp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
